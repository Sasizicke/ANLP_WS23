{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('omw-1.4')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasi\\AppData\\Local\\Temp\\ipykernel_17448\\3708121857.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text().strip()\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove emails\n",
    "    email_pattern = re.compile(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\")\n",
    "    text = re.sub(email_pattern, '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text().strip()\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split(\" \")])\n",
    "    \n",
    "    return text\n",
    "\n",
    "#apply the preprocess_text function to the review column\n",
    "data['review'] = data['review'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the preprocessed text\n",
    "tokenized_text = [review.split() for review in data['review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec Model - CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model on the tokenized text\n",
    "model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Convert the tokenized text to vectors using the trained Word2Vec model\n",
    "# The vector for each review is the average of all the vectors of the words in the review\n",
    "X = np.array([np.mean([model.wv[word] for word in review], axis=0) for review in tokenized_text])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X, data['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec Model - Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model on the tokenized text\n",
    "model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Convert the tokenized text to vectors using the trained Word2Vec model\n",
    "# The vector for each review is the average of all the vectors of the words in the review\n",
    "X = np.array([np.mean([model.wv[word] for word in review], axis=0) for review in tokenized_text])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_skip_gram, X_test_skip_gram, y_train, y_test = train_test_split(X, data['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and run Logistic Regression Model for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the training data\n",
    "def logreg(X_train, X_test):\n",
    "    # train a logistic regression classifier on the training set\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and run Random Forrest Model for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranforr(X_train, X_test):\n",
    "    # Train a random forest classifier on the training set\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and run Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supvecmach(X_train, X_test):\n",
    "    # Train a support vector machine classifier on the training set\n",
    "    classifier = SVC(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the logistic regression model on the testing data\n",
    "def evaluate(y_test_cbow, y_test_skip_gram):\n",
    "    print(\"Accuracy-CBOW:\", accuracy_score(y_test, y_test_cbow))\n",
    "    print(\"Accuracy-Skip-gram:\", accuracy_score(y_test, y_test_skip_gram))\n",
    "    print(\"Precision-CBOW:\", precision_score(y_test, y_test_cbow, pos_label='positive'))\n",
    "    print(\"Precision-Skip-gram:\", precision_score(y_test, y_test_skip_gram, pos_label='positive'))\n",
    "    print(\"Recall-CBOW:\", recall_score(y_test, y_test_cbow, pos_label='positive'))\n",
    "    print(\"Recall-Skip-gram:\", recall_score(y_test, y_test_skip_gram, pos_label='positive'))\n",
    "    print(\"F1 Score-CBOW:\", f1_score(y_test, y_test_cbow, pos_label='positive'))\n",
    "    print(\"F1 Score-Skip-gram:\", f1_score(y_test, y_test_skip_gram, pos_label='positive'))\n",
    "    # Create a confusion matrix\n",
    "    print(\"Confusion Matrix-CBOW\", confusion_matrix(y_test, y_test_cbow))\n",
    "    print(\"Confusion Matrix-Skip-gram\", confusion_matrix(y_test, y_test_skip_gram))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sasi\\anaconda3\\envs\\ANLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_test_cbow = logreg(X_train_cbow, X_test_cbow)\n",
    "y_test_skip_gram = logreg(X_train_skip_gram, X_test_skip_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-CBOW: 0.4987\n",
      "Accuracy-Skip-gram: 0.8691\n",
      "Precision-CBOW: 0.49859606899318093\n",
      "Precision-Skip-gram: 0.863905325443787\n",
      "Recall-CBOW: 0.4972994598919784\n",
      "Recall-Skip-gram: 0.8761752350470094\n",
      "F1 Score-CBOW: 0.49794692038057087\n",
      "F1 Score-Skip-gram: 0.8699970205581488\n",
      "Confusion Matrix-CBOW [[2501 2500]\n",
      " [2513 2486]]\n",
      "Confusion Matrix-Skip-gram [[4311  690]\n",
      " [ 619 4380]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test_cbow, y_test_skip_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaulation CBOW vs skip-gram using logistic regression:\n",
    "\n",
    "As we can see, the performance of skip-gram is significantly better than the performance of CBOW. Almost 3700 more texts are correctly assigned to their respective sentiment category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cbow = ranforr(X_train_cbow, X_test_cbow)\n",
    "y_test_skip_gram = ranforr(X_train_skip_gram, X_test_skip_gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-CBOW: 0.4929\n",
      "Accuracy-Skip-gram: 0.8409\n",
      "Precision-CBOW: 0.4924210526315789\n",
      "Precision-Skip-gram: 0.8345111896348646\n",
      "Recall-CBOW: 0.46789357871574316\n",
      "Recall-Skip-gram: 0.8503700740148029\n",
      "F1 Score-CBOW: 0.47984408657298183\n",
      "F1 Score-Skip-gram: 0.8423659962350143\n",
      "Confusion Matrix-CBOW [[2590 2411]\n",
      " [2660 2339]]\n",
      "Confusion Matrix-Skip-gram [[4158  843]\n",
      " [ 748 4251]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test_cbow, y_test_skip_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaulation CBOW vs skip-gram using logistic regression:\n",
    "\n",
    "As we can see, the performance of skip-gram is significantly better than the performance of CBOW. Almost 3500 more texts are correctly assigned to their respective sentiment category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cbow = supvecmach(X_train_cbow, X_test_cbow)\n",
    "y_test_skip_gram = supvecmach(X_train_skip_gram, X_test_skip_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-CBOW: 0.4994\n",
      "Accuracy-Skip-gram: 0.8698\n",
      "Precision-CBOW: 0.49922958397534667\n",
      "Precision-Skip-gram: 0.863520157325467\n",
      "Recall-CBOW: 0.4536907381476295\n",
      "Recall-Skip-gram: 0.878375675135027\n",
      "F1 Score-CBOW: 0.47537203940473693\n",
      "F1 Score-Skip-gram: 0.8708845696152321\n",
      "Confusion Matrix-CBOW [[2726 2275]\n",
      " [2731 2268]]\n",
      "Confusion Matrix-Skip-gram [[4307  694]\n",
      " [ 608 4391]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test_cbow, y_test_skip_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaulation CBOW vs skip-gram using logistic regression:\n",
    "\n",
    "As we can see, the performance of skip-gram is significantly better than the performance of CBOW. Almost 3700 more texts are correctly assigned to their respective sentiment category"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
